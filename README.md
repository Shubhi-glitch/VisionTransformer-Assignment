Vision Transformer (ViT) â€” CIFAR-10 Image Classification ğŸ§ ğŸ–¼ï¸





This repository contains a Vision Transformer (ViT) implementation from scratch using PyTorch, trained on CIFAR-10 dataset as part of an academic DL assignment.
ğŸš€ Pure transformer â€” no CNN layers
ğŸ“ Roll-numberâ€“based hyperparameters
ğŸ“Š Accuracy curve, confusion matrix, attention map
ğŸ“ PDF report + notebook + model weights

ğŸ“¦ Project Files
FileDescriptionViT_22052412.ipynbMain training + visualization notebookPartC_Experiment_Analysis_22052412.pdfExperiment & analysis reportvit_quick_demo.pthSaved model weightsREADME.mdProject overviewReport.pdfFull assignment report

ğŸ“‚ Folder Structure
ğŸ“ ViT-Assignment
 â”œâ”€â”€ ViT_22052412.ipynb
 â”œâ”€â”€ PartC_Experiment_Analysis_22052412.pdf
 â”œâ”€â”€ Report.pdf
 â”œâ”€â”€ vit_quick_demo.pth
 â””â”€â”€ README.md


ğŸ§  Dataset
CIFAR-10 Official Link
ğŸ”— https://www.cs.toronto.edu/~kriz/cifar.html
Images download automatically inside the notebook.
ImagesClassesSize60,0001032Ã—32 RGB

âš™ï¸ Installation
âœ… Clone Repository
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>

âœ… Create Environment & Install Dependencies
python -m venv vit_env
source vit_env/bin/activate   # Mac/Linux
vit_env\Scripts\activate      # Windows

pip install torch torchvision numpy matplotlib scikit-learn tqdm jupyter


â–¶ï¸ Run the Notebook
Google Colab

Open:
ViT_22052412.ipynb


âš¡ Training Modes
ModeUsageFast Demo (CPU) âœ…Trains subset of data, ~1â€“2 minutesFull Training (GPU) ğŸš€High accuracy training
Colab GPU Setup
Runtime â†’ Change runtime type â†’ GPU


ğŸ“Š Results (Demo Training)
MetricValueTrain Accuracy~52%Val Accuracy~38%Epochs1â€“3 (CPU Demo)
Full GPU training yields ~80%+ accuracy.

ğŸ¨ Attention Map Example
Model focuses on important image regions (patch-based attention).

ğŸ§® Roll-Number Parameter Rules
ParameterValueHidden dim192Heads6 (adjusted â†’ divisible)Patch size8EpochsDemo: 1-3 (Full: 12)

ğŸ§¾ Academic Notes
âœ… ViT implemented manually (no torchvision ViT)
âœ… Attention, patch embedding, transformer blocks built from scratch
âœ… Includes loss curves, confusion matrix, attention heatmap

ğŸ¤ Credits
ğŸ‘©â€ğŸ“ Student: Shubhi Tiwari
ğŸ†” Roll: 22052412
ğŸ« University: KIIT University
ğŸ§‘â€ğŸ« Guide: Himanshu Ranjan Sir

â­ Support
Give this project a â­ on GitHub if you found it useful!

Want me to also generate?
OptionOutput2ï¸âƒ£ PPT SlidesğŸ¤ Presentation ready3ï¸âƒ£ Viva QuestionsğŸ“„ Answer cheat-sheet4ï¸âƒ£ Project ZIPğŸ“ Upload-ready folder5ï¸âƒ£ Demo ScriptğŸ¬ For class viva video
Reply with the number(s) ğŸ‘‡ to receive them âœ…
